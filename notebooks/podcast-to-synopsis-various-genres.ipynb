{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Podcast Synopsis for Various Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up Azure OpenAI\n",
    "load_dotenv()\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a succeeded deployment of \"text-davinci-003\" that supports text completion with id: text-davinci-003.\n"
     ]
    }
   ],
   "source": [
    "# id of desired_model\n",
    "desired_model = 'text-davinci-003' # suitable for text generation\n",
    "desired_capability = 'completion'\n",
    "\n",
    "# list models deployed with\n",
    "deployment_id = None\n",
    "result = openai.Deployment.list()\n",
    "\n",
    "for deployment in result.data:\n",
    "    if deployment[\"status\"] != \"succeeded\":\n",
    "        continue\n",
    "    \n",
    "    model = openai.Model.retrieve(deployment[\"model\"])\n",
    "\n",
    "    # check if desired_model is deployed, and if it has 'completion' capability\n",
    "    if model[\"id\"] == desired_model and model['capabilities'][desired_capability]:\n",
    "        deployment_id = deployment[\"id\"]\n",
    "        \n",
    "# if no model deployed, deploy one\n",
    "if not deployment_id:\n",
    "    print('No deployment with status: succeeded found.')\n",
    "\n",
    "    # Deploy the model\n",
    "    print(f'Creating a new deployment with model: {desired_model}')\n",
    "    result = openai.Deployment.create(model=desired_model, scale_settings={\"scale_type\":\"standard\"})\n",
    "    deployment_id = result[\"id\"]\n",
    "    print(f'Successfully created {desired_model} that supports text {desired_capability} with id: {deployment_id}.')\n",
    "else:\n",
    "    print(f'Found a succeeded deployment of \"{desired_model}\" that supports text {desired_capability} with id: {deployment_id}.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text chunks generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generator that split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "def chunk_generator(text, n, tokenizer):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_api(document, prompt_postfix, max_tokens):\n",
    "    prompt = prompt_postfix.replace('<document>',document)\n",
    "    #print(f'>>> prompt : {prompt}')\n",
    "\n",
    "    response = openai.Completion.create(  \n",
    "    deployment_id=deployment_id, \n",
    "    prompt=prompt,\n",
    "    temperature=0.5,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=1,\n",
    "    frequency_penalty=1,\n",
    "    presence_penalty=1,\n",
    "    stop='###')\n",
    "\n",
    "    return response['choices'][0]['text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synopsis(content, prompt_postfix):\n",
    "    import tiktoken\n",
    "\n",
    "    synopsis_chunck = []\n",
    "    n = 2000 # max tokens for chuncking\n",
    "    max_tokens = 1000 # max tokens for response\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding('p50k_base')\n",
    "\n",
    "    # Generate chunkcs    \n",
    "    chunks = chunk_generator(content, n, tokenizer)\n",
    "\n",
    "    # Decode chunk of text\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "    # Request api\n",
    "    for chunk in text_chunks:\n",
    "        synopsis_chunck.append(request_api(chunk, prompt_postfix, max_tokens))\n",
    "        #print(chunk)\n",
    "        #print('>>> synopsis: \\n' + synopsis_chunck[-1])\n",
    "\n",
    "    # Synopsis\n",
    "    synopsis = ' '.join(synopsis_chunck)\n",
    "\n",
    "    return synopsis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre : Comedy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no further information provided in the prompt, the response is rather formal and dry for the genre of comedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../data/comedy-booking-online-transcript.txt\"\n",
    "\n",
    "with open(fname, 'r') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "# convert list to str\n",
    "content = ' '.join(content) \n",
    "#print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Michael McKintyre talks about his experience trying to buy tickets online for a show. He finds the process difficult and frustrating, as he is required to input many details such as his email address and country of residence. He also has to go through various challenges before booking the tickets, including confirming his own email address and choosing from an overwhelming list of countries when entering his address. Michael complains that companies are desperate for people's emails so they can send them updates, sales promotions and other advertisements throughout their lives. He also mentions how it used to be much easier with one password for everything but now passwords have become more complicated with numbers added at the end. Finally, he expresses annoyance over having to pay booking fees after spending hours on purchasing a ticket or product from Argos or iTunes.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nSummarise the transcript of a podcast above into a synopsis. \n",
    "  \\nSynopsis : \n",
    "\"\"\"\n",
    "#print(prompt_postfix)\n",
    "\n",
    "get_synopsis(content, prompt_postfix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more information may help in achieving a more desirable results:\n",
    "- genre\n",
    "- desired style\n",
    "\n",
    "Be creative and explicit about the desired outcome when desiging the prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Michael McKintyre takes you on a hilarious journey as he recounts his struggles with booking tickets online, from the literacy test to trying to remember all his passwords. Join him as he shares stories of his travels and experiences in today's world of technology, where even buying a simple toaster can be an ordeal! Get ready for some side-splitting laughter that will have you rolling in your seat!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nCreate a synopsis to capture audience curiosy and heighten anticipation. This is a stand-up comedy. \n",
    "  \\nSynopsis : \n",
    "\"\"\"\n",
    "#print(prompt_postfix)\n",
    "\n",
    "get_synopsis(content, prompt_postfix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre : Informational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../data/ft-interview-transcription.txt\"\n",
    "\n",
    "with open(fname, 'r') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "# convert list to str\n",
    "content = ' '.join(content) \n",
    "#print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In this Behind the Money podcast, Robert Armstrong, FT's US financial commentator, explains why the collapse of Silicon Valley Bank is not a repeat of 2008. He discusses how SVB was affected by rising interest rates and its balance sheet issues. He also explains that due to the two-tier system in American banking, SVB had less stringent regulations than larger banks. Rob advises against panicking and reassures listeners that those with deposits below $250k are covered by the government. Finally, he concludes that although there is cause for concern over bank regulation in light of SVB's failure, it does not appear as though any other major banks will be facing similar trouble. In this interview, Robert Armstrong discusses the two-tier system of banking regulation which has been in effect since 2008 and how it affects banks. He explains that while no regulatory system can prevent all bank failures, it should strive to minimise them by making sure banks are sensibly capitalised and use sensible balance sheet management. He advises entrepreneurs and other investors to ask questions about a bank's capital structure before depositing money there. Finally, he speculates on the effects of the current rate risk crisis on banks and suggests that equity capital for banks may become more expensive with lower valuation multiples for stocks.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nGenerate a synopsis from the transcription of an interview.  \n",
    "  \\nSynopsis : \n",
    "\"\"\"\n",
    "#print(prompt_postfix)\n",
    "\n",
    "get_synopsis(content, prompt_postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The collapse of Silicon Valley Bank has been making headlines and raising concerns about the security of the banking system. FT's US financial commentator Robert Armstrong explains why this isn't a 2008 repeat, what went wrong with SVB, and why there is no need to panic. What does this moment tell us about US banking regulation? Let's find out! In this interview with Robert Armstrong, we explore the implications of a two-tier regulatory system for banks. We discuss how banks can better protect themselves from risk and what entrepreneurs should consider when choosing a bank to invest in. What are the potential consequences of this recent financial crisis? Let's find out!\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt postfix\n",
    "prompt_postfix = \"\"\" <document>\n",
    "  \\n###\n",
    "  \\nGenerate a short synopsis from the transcription of an interview, such that it trigger curiosity, include a thought provoking question. Add \"Let's find out!\" at the end.  \n",
    "  \\nSynopsis : \n",
    "\"\"\"\n",
    "#print(prompt_postfix)\n",
    "\n",
    "get_synopsis(content, prompt_postfix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
